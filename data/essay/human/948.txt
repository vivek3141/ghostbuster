Bankers used to determine if a person was worthy of being granted a loan or not. The criteria for granting loans were based on the applicant’s habits and relationship with the bankers. People close to the bankers were granted loans causing women and minority ethnic groups to suffer. The loaning system changed when Earl Isaac and Bill Fair invented a system known as FICO. FICO used algorithms to determine the defaulting chances of a loan applicant by comparing their income and expense records. Credit agencies like Equifax use the FICO model to identify default customers. Credit scores are clear, and its industry is regulated, unlike the modern e-score, which is vague and unregulated. E-score algorithms use data like real estate, websites, and items purchased to determine the e-score rating. For example, wealthy estates are given more ratings than poor ones. Since it is illegal for organizations to use credit scores for marketing, companies tap into massive unregulated personal information they use in the marketplace. The E-score model uses proxies that categorize people into races, and if someone’s race turns out to have criminal, the person is considered unworthy of loans.
Data scientists should be taught that including race and zip codes in ethics classes is unfair and unethical when building E-score models. Statistics models have always been efficient in the modern world. However, the models sometimes fail, and the victims are seen as collateral damage. Creditworthiness is no longer about the ability to pay debts, as companies use credit reports to make different versions of credit scores which are then used as proxies. Credit scores have increased poverty because most employers use credit checks to hire employees. Consequently, some states passed laws to ban credit checks to reduce the poverty gap between whites and African Americans.
In low-economy setups, critical decisions are automated, making humans prone to computer errors. Minimal data regulation has led to the purchase and sale of data between corporations and data brokers. Despite efforts by the FTC to push for transparency, data brokers still display minimal information when they ask for their details. Automation of data scraping systems and algorithms has led to mistaken identity cases because computer errors are inevitable, hence the need for fine-tuning data algorithms. Algorithms for E-score, predatory loans, and recidivism sentencing models predict the past into the future, making the poor poorer. Data brokers should use algorithms to ensure that people’s profiles are correct and fair.
The crediting system has evolved as Facebook has created a better credit rating system entirely dependent on people’s social networks. Banks have also started to use people’s data to increase their revenues. However, banks are regulated, making profiling people a risky strategy. Banking regulations force newcomers in finance to go with the unregulated route. Douglas Merrill, former Chief Operating Officer at Google, wants to replace payday lenders with a lower-interest system. Zest Finance buys people’s data and uses it to create a credit rating system. Many ideas built on the Weapons of Math Destruction are doomed to fail. For example, Lending Club and Prosper generated $10 billion in a $3 trillion market despite having E-scores better than the credit score systems. Their stunted growth is because 80% of the money in their platforms is institutional money. Banks use peer-to-peer platforms to escape banking regulations and create their E-score rating systems.
Loan disbursement systems have changed with time and have become more effective. Credit score systems have proven to be more effective than E-score models. Data brokerage algorithms are prone to computer errors that deny loan disbursements to people from poor regions. Companies like Zest finance want to reduce people’s loan interest. Banks use platforms such as Zest Finance to escape banking regulations.