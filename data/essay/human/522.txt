Test reliability is one of the criteria for test quality. It shows how accurately the test is guaranteed to measure the phenomenon under study. Reliability is usually determined after the test items have been analyzed and the final test form has been compiled; a special test validation is conducted to determine it (Whiston, 2017). A test can be called reliable based on two kinds of information. First, a test is called reliable if it is interference-resistant. When the test is administered under different conditions, it gives similar results. Second, a test is reliable if it is internally consistent (homogeneous). That is, there are no inconsistencies within the procedure itself, and the methodology for analyzing the results is chosen correctly. Test reliability is also closely related to random error.
Like any human activity, testing contains errors. The following types of errors occur in testing: lapses, systematic, and random errors. Random errors occur when successive measurements of a constant characteristic yield different numerical values. When determining random errors, it is assumed that the measured characteristic does not change in time, and all deviations are caused by measurement inaccuracy. The boundary between random and systematic errors is conditional. The total error of any test consists of errors of these two types but in different ratios. The relative weight of each type of error depends on the test’s quality and the examination conditions.
Test results always contain errors, no matter how carefully administered the test is. However, using methods of mathematical statistics, it is possible to estimate the magnitude of the total test error and use it to assess test reliability. Without a statistical evaluation of test reliability, measurement results cannot be considered reliable. Therefore, test reliability is a characteristic of the extent to which differences between test-takers reflect differences in test-takers’ properties and the extent to which they are a reflection of random errors.