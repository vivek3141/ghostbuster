The use of open source software is becoming a standard part of everyday life. In January 2006, over 67% of websites run on the open source Apache [10]. A quarter of web surfers use Mozilla Firefox, Linux is going from strength to strength, and OpenOffice has been downloaded by over 40 million people [11]. We shall be looking at what makes open source software popular, at open source hardware, open data standards, and how copyright and patents will affect them.
Firstly, what is open source? Bruce Perens defines software as open source if it can be distributed freely with intelligible source code that can be modified to create derived works. Transferred with the program should be a non-discriminatory license that should restrict no other software [9].
This, as a broad definition, is accepted by most of the open source community. There is much discussion, however, about the details. The major sticking point seems to be whether software that is free to use and modifiable to all can be modified and included as part of a closed source application.
Perhaps the most famous example of this is Apple building their operating system OS X on top of Unix, and selling the result. Apple itself writes open source software under the Apple Public Source License [17], which is now recognised by the Open Source Initiative.
The word "free" is also of particular import here, as it refers to freedom rather than gratuity.
The cost of open source software is the subject of much debate. While licenses are usually either free or of little cost relative to proprietary software, it is often more expensive in other areas. A report made by Cybersource found that in a model of a company purchasing the hardware and network infrastructure for 250 users, Microsoft Windows was only 122% more expensive than Linux. While software licenses under Linux were 0.017% of the cost of the Microsoft counterparts, the ongoing operational costs of Linux were 128% higher than Microsoft [8].
Another report found that the total cost of operation (TCO) of a Linux server is 41.3% higher than Microsoft Windows Server 2003, although the TCO of a Linux web server is 8.3% lower than Microsoft Windows [7].
A third non-sponsored report finds that 88% or corporations report that Microsoft Window Server 2003 provides reliability that is equal to or greater than Linux, and recovers 30% faster from security attacks [6]. This raises a very interesting point about the security of open source software.
The threat of open source software containing Trojan horses or backdoors is one of the biggest limiting factors for open source adoption [13]. This threat is not actually particularly significant, however. As Mike Curtis pointed out, there is usually such a large body of people examining open source software to identify and provide corrective action that a vulnerability wouldn't last long.
It has been strongly argued that open source software is more reliable [5]. An axiom of NASA is that "software is not software without source code", meaning that they cannot trust mission-critical software if they have not got the source code.
Open source software is more creative [5], more rapidly evolving, has less overhead and bureaucracy, and helps to prevent monopolies. Without the need for secrecy, more consultation can be done, and ideas can be formed with co-operation rather than competition. Also, as Jerry Brady says, there is less concern for marketability, and more concern for quality of code.
Open source is not all positive, however. As software evolves rapidly, there is a risk of fragmentation into many conflicting versions. Also, the fact that the open source programmers are often hobbyists [14] means that there is often a tendency to have lots of activity on the interesting bits of code, while the more mundane areas are not done. For this reason, applications that don't have general usage or interest, for example a specific scientific application, is very unlikely to survive as an open source initiative.
In some areas, however, the opposite is true. Because the third world cannot often pay research and development costs, only 1% of funding pays for research into tropical disease. Therefore an open source paradigm has been applied to drug manufacture, with institutions working together worldwide, and already there has been results in curing Schistosomiasis [16].
But what of hardware? What makes hardware open? For hardware to be open, all information on using the hardware and its software interfaces must be available. Also, all information to interface the design from all points of view must be documented and available, for example drivers, sockets, connectors, pin assignments, FPGAs, bit streams and CPU instructions [18].
There are major differences between open source hardware and software, and not least is the fact that it costs to fabricate hardware, whereas compiling software is usually free. The other cost is the fact that you need EDA (electronic design automation) tools. Although there are some open EDA tools they are not generally trusted enough to be used for something project dependent [19].
The main advantage to open architecture is that it allows the design of a core that verifies system specifications and is compatible with other developments, sharing know-how and experiences with other designers. A disadvantage is the fact that open hardware often seems to be more unstable [4].
The development time and cost of systems can be reduced by reusable verified open design cores where the debugging is shared between designers. Having hardware open also means that it easier for other companies to make good software that interfaces well with it.
The Basic Local Alignment Search Tool, BLAST, is used to search for sequence similarity in genomic databases. Research done into making BLAST more efficient by making an open source chip to do a small but computationally important part of the code in hardware was decided to be currently not cost effective, but given the current trend in decreasing costs of hardware it is forecast to be cost effective soon. This has been seen as an indicator to the future of open source hardware. [24]
Many organisations have been more successful currently, however. Vivace Semiconductor have used an open source RISC core in their new video processing chips. Opencores.org lists a number of active and complete open source hardware projects, including cores for arithmetic functions, communications protocols, memory, DSP and microprocessors [20].
Power.org is a community of over 40 companies and 10,000 developers aiming at developing open source hardware around IBM's Power PC architecture [21]. A recent success was the announcement of the silicon validation of a new design approach that will give a 30% increase in processor power and 40% reduction in chip area.
Another area of openness in computer science is open and public data standards. There is a distinction here. A public data standard is publicly documented and freely available, for ensuring interoperability between different applications, for example RTF and PDF formats for documents.
An open data standard is to ensure interoperability between different solutions that need to operate on the same data, written by super partes organisations, publicly documented and freely available for adoption, for example HTML [22].
A closed data standard is one that is not publicly documented and freely available. Although closed data standards might make sense from a business perspective, it arguably violates fundamental principles of data ownership and control [3]. Applications that use closed data standards often provide a mechanism to export the data to other programs in a crude format, but this often strips away a lot of information created by the software itself. Closed formats also encourage monopolies.
There is a fundamental law of computer science, 'only put into a system what you know you can get out'. If you store critical data in a closed file format, and the company responsible fails, you are left with unusable data. Without being maintained and updated, most older software will not run on the latest hardware, and keeping an old computer in order to keep access to your files is not usually practical.
Another point is simple communication. If you send a closed format file to a contact, the recipient will probably not be able to access the contents unless he or she has the same particular piece of software that you have. If you send an open file, there is much more chance they'll have an application to access the data.
There is also no way of knowing what a closed file contains. Inside a closed document file there could be the author's name, their operating system, maybe even passages of text that were deleted [23].
Open source software, by definition, use open and public data standards. Proprietary software is slowly starting to accept them more and more, in order that software may be seen to be as flexible, and therefore as useful as possible.
The biggest threat to open source software, and then by implication open data standards, is probably patenting. If a developer inadvertently uses a piece of source code that is protected by a third party patent, then his or her company and customers may be exposed to intellectual property lawsuits [24].
The most prolific case was when SCO mailed Fortune 1000 corporations using Linux, demanding that they pay them license fees in relation to the SCO's intellectual property of the Unix source code. Interestingly, the SCO made no patent claims, merely copyright.
The Linux distributor Red Hat has addressed the issue by pledging that if any of its code is found to be infringing intellectual property, it will replace the code for its customers.
A paper investigating Linux patent risk found that there is a "level of patent infringement that Linux users and developers should be mindful of and prepared to address". The study also found that 283 software patents not reviewed by courts could potentially be used to support claims of infringement against Linux. This is, however, comparable to proprietary software such as Microsoft Windows. [33]
A study found that 4% of US companies have been faced with the threat of vendor legal action over intellectual property infringement. This increases to 8% for firms with annual revenues greater than $750 million [32].
The question of whether software can be patented is currently a very contentious one. In Japan and America it can be (see later), but in Europe the matter is grey.
Under the European Patent Convention, "computer programs as such are excluded from patentability" [1]. Since the EPC came into force in 1978, however, more than 300,000 software related patents have been granted [25].
In order to rectify this contradiction, a directive on the patentability of computer-implemented inventions has been proposed. It states that in order to be patentable, "an invention that is implemented through the execution of software on a computer or similar apparatus has to make a contribution in a technical field that is not obvious to a person of normal skill in that field" [26]. This directive is supported by Microsoft, IBM, Hewlett-Packard and the European Patent Office.
The directive was extremely controversial, and when the European Union invited consultation it received 1,447 responses over 2,500 pages of text. They received responses from every EU and EEA member state except Liechtenstein. In general students, academics, engineers and small companies were against the proposal, and lawyers, established industry players and government agencies were in favour [27].
The Kiel Institute for World Economics stated that "The extension of patent law to the field of software represents a fundamental threat to the open-source development model". Even Bill Gates, whose company applied for 3,000 software patents in 2004 alone, said in 1991 that "if people had understood how patents would be granted when most of today's ideas were invented and had taken out patents, the industry would be at a complete standstill today".
The general consensus amongst the open source community was that the law would hurt open source innovation [29, 30].
NoSoftwarePatents, an NPO funded by Red Hat and MySQL, said that "Patents turn software publishing into the privilege of a few" as only large corporations are equipped to deal with the incremental costs and legal risks" [28]. Patents are valid for 20 years, which means that a "groundbreaking idea in the days of the Commodore 64 should still enjoy patent protection today" [28].
In February, the European Parliament rejected the directive.
It is worth pointing out at this stage the difference between patent and copyright, when it comes to software. Patents would apply to the underlying technical ideas and methods, and copyright to the actual code. It is far easier to alter a piece of code sufficiently so that it does not infringe a copyright, but it is far too difficult to alter it fundamentally enough to avoid a patent.
But what of the rest of the world? In Japanese law, the invention has to be a "highly advanced creation of technical ideas by which a law of nature is utilised", and in the US any invention is patentable as long as it is "within the technological arts" and provides a "useful, concrete and tangible result".
There is no evidence that Japanese independent software developers have been unduly affected by the patent positions of large companies or of others [31]. There is, however, concern that patents in the US are being granted on trivial and old ideas, that patents are strengthening the market position of the big players and that the computer program related industries are examples of industries where incremental innovation occurs and that there are serious concerns whether, in such industries, patents are welfare enhancing [31].
What about patent pooling? It has been observed that technical standard setting and patent pools potentially raise competition policy issues since they are established through a cooperative act among private companies in a free market [36].
Recently, the patent debate has become directly relevant to data standards. Forgent Networks acquired the patents of the technologies behind the JPEG data compression algorithm and data standard when it bought Compression Labs Inc. in 1997. It has recently claimed and received royalties from two corporations, including Sony. [35]
Forgent claims the sole and exclusive right to use and licence JPEG in all "fields of use" except in the satellite broadcast business. These "fields of use" include digital cameras, digital still image devices, PDAs, cellular telephones that download images, browsers, digital camcorders with a still image function, scanners and other devices used to compress, store, manipulate, print or transmit digital images. [15]
In conclusion, therefore, the evidence points towards open source software, and, to a lesser extent, hardware, being in general a mutually beneficial paradigm. Open data standards are very beneficial to the end user. Patents seem to stifle the open source movement, and it is more difficult to see how they would be beneficial to the end user.
I must admit to having found this task enjoyable. I read quite a wealth of journals and papers before embarking, so the content just flowed when actually writing the essay. The most difficult aspect of the task I found was the word limit. I always find word limits difficult. I either run out of steam before the end and am faced, as I am now, with another 400 words and no ideas, or I have so much to cram in that I have to leave swathes out.
The content I wanted to include took over 3,000 words, so I had to edit out quite a lot of information. The main section I removed was details of patenting laws in other countries, such as India's new amendment. There was also a great deal of discussion about Munich deciding to install Linux and OpenOffice on its 14,000 computers rather than updating the Microsoft software, then stalling because of the patent issues. I reduced the number of references from 42 down to 35.
The conclusion was also a bit of a victim in my editings, bringing it down to one small sentence for each of the areas of discussion. I decided this would be appropriate as I felt the actual content of the essay is more important than repeating myself in a summary.
I enjoyed the Blackboard forum posting. Posting on fora is not something I tend to do, but it was strangely enjoyable. It is very difficult to make more than one point in 200 words, so it is all about conciseness. The problems with restricting to 200 words are far fewer than restricting to 2,500 as it is far more obvious what to remove to reduce the word count.
I chose 'Sex and Technology' as a topic, and started threads about paedophilia, homosexuality online, and telephone scatalogia. I found it difficult to draw the line between what is acceptable to discuss in an academic way, and what is not. I may have tended more toward the latter than the former, but not excessively so. I also found it slightly difficult to reply to people who were ignorant or have viewpoints arguably clouded by fundamental religion.
In all, I found the assignment gently enjoyable and quite interesting.