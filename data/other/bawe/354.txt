Table 1 (in the appendix) is the summary statistics of some of the variables in the model. Do note that the 'count' is different for different variables since the dataset wasn't complete. It could be that when answering the survey, the option 'n/a' was chosen or not filled in at all. Hence when Stata does calculations and model estimates, it leaves out those missing observations. I do not believe in adding in arbitrary figures to replace those missing values. This would lead to biased results especially since Diploma students didn't take the QT test.
The mean qtmark is 64.9 while its median is 65 and standard deviation is 13.1. Out of the whole sample population of 408 people, only 388 reported their marks. Looking at the number of hours students attending classes and lectures (attl, attc, attr) in general, attendance ranged from 0% to 100%, with lecture and class attendance being on average 80.9 and 82.4 percent. Meanwhile average revision lecture attendance was much lower at 47.2%.
Table 2 (also in the appendix) shows the correlation between some of the variables that I consider important or interesting in the model. Note that the correlation coefficients of attl and attc, as well as hrsall and hrsqt are relatively high (0.646 and 0.498). Hence when choosing the model in question 6, I would have to take this into account. At the same time, the other variables seem to be relatively correlated to qtm ark, hence they ought to make good candidates for explanatory variables. For instance the correlation coefficients between qtmark and attl, attc and hrsall are 0.226, 0.283 and 0.134.
Table 3 shows the mean mark in some subsamples. From the table, it can be inferred that it could be possible that for example, being a female would imply a lower test mark (65.4) compared to a male (63.8). Between years, the average marks are also different - 1999(66.9), 2000(63.3), 2001(61.7) and 2002(69.3). Still, more testing need be done to verify this.
I have decided not to include any cross plots of variables. After trying out a few, I have discovered that there aren't any interesting features to note and the variables don't really show any significant correlation in a 2- dimensional graph. Perhaps if it were possible to represent a multivariable cross plot, more interesting features can be observed.
Observing the data, I noticed that there were quite a number of outliers. For instance, while everyone who had filled up their marks obtained double-digit marks, student number 86 had 8 marks (Table 1). The next lowest mark was 36. Then there are those who have answered that they have 87 and 17 A grades at A-levels. They must have been some kind of wunderkind. At the same time, there were those who obtained more A-level A grades than the number of A-levels they had, which is impossible. Unfortunately, I didn't do anything to remedy the presence of these outliers simply because eliminating them would oft require some kind of value judgment.
Here, we are asked to calculate separate bivariate regressions of exam performance against the three attendance measures.
Using Stata, the estimates of the equations are as follows (standard errors in parentheses, t-ratios in square brackets):
Equation E1e shows that for a given 1 percentage point increase in lectures attended, qtmark is expected to rise by 0.145 percentage points. Hypothetically, if a student does not attend any lectures, his estimated qtmark would be 53.3%, although one should be cautioned that care should be taken when interpreting this intercept coefficient since interpreting it might imply extrapolating beyond which this model estimate holds true.
Equation E2e shows that for a given 1 percentage point increase in revision lectures attended, qtmark is expected to fall by 0.002 percentage points. If the student does not attend any of these revision lectures, he's expected to obtain a mark of 65. The same caveat applies here.
Equation E3e shows that for a given 1 percentage point increase in classes attended, qtmark is expected to increase by 0.167 percentage points. If he does not attend any classes, it is estimated that his mark would be 51.3%. Again, the same caveat applies.
To test whether exam performance is related to the separate attendance measures, separate tests are done on the respective slope coefficients. We use the one-tailed t-test since we are interested in knowing whether attendance has any positive impact on performance.
Given a particular significance level, we reject the null hypothesis of a test if its t-statistic exceeds the critical values given in statistical tables.
The critical values at 1% significance level is t378,1%=2.33 and at 5% is t378,5%=1.65.
Comparing the t-statistics from the equation E1e it appears that at both 5% and 1% significance levels, we reject the null hypotheses that exam performance is not related to lecture attendance. Hence at these significance levels, lecture attendance affects exam performance. Similarly the same conclusion can be made about class attendance (E3e).
On the other hand, at both significance levels, we accept the null hypothesis that there is no relationship between exam performance and revision lecture attendance.
Next, using the same three attendance measures as above, a single multivariate regression is performed. Exam performance is modeled as follows:
E4
Stata yielded the following regression estimate:
E4e
Equation E4e shows that for a 1 percentage point increase in lecture attendance, qtm ark would rise by 0.0597. Similarly for a 1 percentage point increase in revision lecture attendance, qtmark is expected to fall by 0.03 98 points, while 1 percentage point increase in class attendance yields an extra 0.152 points in exam performance. Should a student not attend any of the lectures or classes, his expected qtmark would be 49.3 points. The same caution should be applied here as that made earlier in question 2a.
Again, testing separately on each slope coefficient, we conclude that at 1% significance level, we reject the null hypothesis that class attendance is not related to exam performance. However, we both accept the null hypotheses that lecture and revision lecture attendance has a non-positive impact on exam performance at both 1 and 5 percent significance levels.
HA: At least one of the coefficients  is different from 0.
To test the joint significance of the explanatory variables, an F test is performed.
Using the calculated R 2 value of equation E4 provided by Stata (refer to Appendix 2 for the method of calculation), the F statistic is calculated to be 13.07. The critical value of this test at 1% significance level is
given as F3,366,1%=3.78.
Hence the null hypothesis that the model has no explanatory power is rejected. We thus conclude that at least one of slope coefficients is not equals to zero (which is consistent with the previous t-test).
The relationship between exam performance and lecture attendance and the number of As at A-level is given in equation E5. Extending this model, to test whether students from different years did differently in their QT tests, the dummy variables yr99, yr00, yr01 for the years 1999, 2000 and 2001 were created (E6). This would mean that 2002 would be the 'base year'.
E6
Estimates of the regressions:
E6e
E5e
Looking at model E5e, a student who increases lecture attendance by 0.143 percentage points increases his marks by 0.143 points. Should that student have obtained an extra A grade at A-level, his qtmark is expected to be 0.03 69 points higher. If a student in 2002 never went for any lectures and had no A grades at A-level, he'd be expected to get a mark of 57 percentage points.
A student in 1999, who attended a given amount of lectures and number of As, is expected to get 1.191 marks less than if he were in 2002. Similarly a student in 2000, who attended a given amount of lectures and number of As, is expected to get 5.185 marks less than if he were in 2002. A student in 2001, who attended a given amount of lectures and number of As, is expected to get 6.854 marks less than if he were in 2002.
To test if the students from different years performed differently, the following hypothesis is used:
H0 :  =  =  =  = 0
HA: At least one of the dummy variable coefficients  is different from 0.
Since the extra dummy variables were added in E6, it is the unrestricted model. E5 meanwhile is the restricted model. The following F statistic was obtained
At 1% significance level, F3,343,1% given by the tables is 3.78. Thus we reject the null hypothesis that the additional dummy variables have no effect on qtmark. Thus for some years, there is a significant difference in exam performance compared to other years.
Separate regression estimates of E5 for each of the four years were made, and were modeled as follows:
E7iv
Stata yielded the following equation estimates:
To test for coefficient constancy across the four years, a Chow test is performed:
H0 :  =  =  =
HA : At least one of the equalities do not hold true
Essentially, this test is just comparing model E7 with E5. The RSS (residual sum of squares) of the unrestricted model E7(i-iv) is just the sum of all the RSS of each subsample. It is calculated to be 47127. The restricted model E5 meanwhile has an RSS of 55856.
The F statistic is calculated to be 6.94. From the tables, F9,337,1%=2.41. Hence we reject the null hypothesis that all the coefficients are the same across the subsamples. Hence we conclude that there is a significant improvement in the fit on splitting the sample and that we should not use the pooled regression.
Here we test to see whether or not only the slope coefficients of model E7 are the same. Hence we should compare this to another model with same slope coefficients with different intercepts for different years (intercept dummy variables) i.e. model E6.
Thus the restricted form is equation E6 while the unrestricted is E7.
H0 :  =  =  =
HA : At least one of the equalities do not hold true
Performing a Chow test again, with the RSS of the unrestricted model E7 given as 47127 and the restricted model 53240, an F statistic of 7.29 is obtained. From the tables F6,337,1%=2.80. Hence we reject the null hypothesis that all the slope coefficients are the same across the subsamples. We thus conclude that there is a significant improvement in the fit after allowing slope coefficients to vary, given that different years have different intercept dummy variables.
Gujarati (1998, p.406) suggests that a good model ought to be parsimonious, i.e. it should be kept as simple as possible, consistent with Occam' s razor. It should also be identifiable, has a good fit and be theoretical consistent. In addition to that, the model should have predictive power. Hence when choosing what variables to include, and in what form, I have resisted the temptation to include too many variables into the model.
In general, I chose the variables through trial and error, although these choices were subject to theoretical consistency. I avoided adding too many variables since many of the variables are highly correlated to each other, hence avoiding the problem of multicollinearity. Although I used the R 2 and adjusted-R 2 values to indicate whether I was heading in the right direction, that is in obtaining better fits, I also maintained that better fits (higher R 2 values) do not necessarily imply better models. Throughout the selection of the model, I kept in mind Occam's razor which suggests that we should keep models as simple as possible.
I have thus reached the conclusion that the following model would be a suitable one to estimate exam performance:
E8
And the estimqates of the equation:
E8e
This equation estimates that for a unit proportional increase in the number of classes attended, the exam mark is expected to be 6.41 marks higher. Compare this with model E3 where there is no transformation of the class attendance variable, where in that case the interpretation of the slope coefficient is that for a unit increase in classes attended, the exam mark would rise by 13c. I feel that using ln attc rather than attc would be better since I believe that there is diminishing returns to class attendance.
Considering my own experience, I have found many lectures to be uninspiring and not useful - having little influence in my understanding of material. Confirmed by my testing whether my personal experience is consistent with the data, I have decided to drop completely lecture attendance from my model. At the same time, the correlation between lecture attendance and class attendance is quite high (0.28) and by dropping this variable, I may increase the efficiency of the model.
The coefficient of the ratio of number of A grades at A-level over the number of A-level passes is calculated to be 9.13. This ought to be a better indicator of A-level performance rather than the just taking number of A grades since different people take different number of A-level subjects, hence the ratio would be a better indicator of A-level success. Of course, this is assuming that students don't fail any subjects (here I am taking number of A-levels as a proxy of number of A-level subjects taken).
Next I include a transformed of the average number of hours spent studying per week (ln hrsall). Like class attendance, I believe that the number of hours studying also experiences diminishing returns.
Not everyone taking the survey was in the typical age group of 19-20. Some students work a few years before going back to university while others child prodigies leave school earlier. I hypothesized that those who continue studying after working a few years are at a disadvantage (they may have forgotten the mathematics they learnt earlier, or it could be that older students are, the less used they are to taking tests and studying for them, or simply because the brain works less well the older one gets). True enough, the estimate of coefficient of ln age is -9.75 and with a high t-statistic.
Considering students from different years face different exam questions, I included the dummy variables for the years 2000 and 2001. 1999 was excluded since adding a dummy variable didn't significantly improve the fit. Looking at the coefficients of these dummies, it could be casually suggested that perhaps the exams in these two years were exceptionally tougher than that in 1999 and 2002, or perhaps the students in these batches were exceptionally less bright.
Before adding the dummy variable for the UK, I was expecting UK students to have some advantage over international students. UK students have a better command of English and they do not have to experience great changes in their lifestyles. On the contrary, the equation estimates show that being a UK student, your expected mark would be 5.7 less than an international student. Trying to explain this, I guess that perhaps it is the brighter batch of students in each country that qualify to go abroad to study here, whereas in the UK, Tony Blair and Labour's policy of trying to push everyone (even those not suited for it) through university education has caused a deterioration in the quality of UK students overall.
I also included the dummy variables econ, which identifies students who take straight economics (as opposed to other variants of it) and mathpass (which wasn't defined in the question, although I suppose it is a pass in math at A-level). It is pretty obvious that those who have done well in math examinations in the past would continue to do so in the future. I added the dummy variable econ since the prerequisite for this course is a high math grade and I assumed that those in straight economics would be those who have a greater interest/liking for math. True enough, the coefficients of these variables are positive and significant.
The R 2 and adjusted R 2 values of this model are 0.231 and 0.207 respectively, which means that 23% of the model can be explained by the independent variables, which I feel is a "fair" value, considering the tradeoff between a high R 2 value and the number of variables. Performing the goodness of fit test, I obtained F=9.43 which is greater than the critical value F9,282,1%=2.41. Hence it can be said that the variables in the model do have significant joint explanatory power.
A few caveats need be made with regards to the regression outputs. Since the dataset survey.xls wasn't complete (there were quite a number of missing values), Stata computations restricted samples to only observations that had were complete for any particular regression estimate. So, in general, equation estimates with different variables had different numbers of observations, and the greater the number of variables in an equation estimate, the harder it was to find complete observations, hence the lower the number of observations.
There are many variables that explain a particular person's exam performance. A good attempt to model exam performance thus has to be one that tries to encompass as many of these variables while still keeping things simple (in the number and choice of variables). Some skepticism should also be applied to the quality of the survey - the incompleteness of the data, the way questions were phrased, the inclusiveness of the whole population.