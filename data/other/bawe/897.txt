A safety-critical or safety-related system comprises everything (hardware, software and human elements) necessary to carry out one or more safety functions, where failure of the safety function would give rise to a significant increase in the risk to the safety of persons and/or the environment. [1]
Safety is the freedom from unacceptable risk of physical injury or of damage to the health of people, either directly or indirectly as a result of damage to property or to the environment. [2]
A Safety Related System is any system whose malfunction, either directly or indirectly, has the potential to lead to safety being compromised.
Within this scope, a Safety-Critical System is defined as:
Thus a Safety-Critical System presents a direct threat to human life, in the event of a failure. A very small software fault, such as an uninitialised variable in the program, can cascade unto an hazard.
For this reason the safety critical software development lifecycle is distinctly different from that used for other regular software. Because special consideration to safety is given at all stages of development.
Many high-availability systems do not threaten human life in cases of failure and instead are designed to maximize uptime and minimize downtime.
But safety-critical systems don't always strive to maximize uptime. In fact, they may intentionally take themselves down or bring some subsystems down in situations where there is a threat of injury or loss of life.
For safety-critical systems, a thorough hazard analysis and risk analysis must be done before architectural design can be done. The objective is to systematically identify the dangers to human safety that a system may pose, including an evaluation of the likelihood of an accident resulting from each hazard.
The Safety Integrity Level determines the measures that need to be taken against both systematic and random hardware failures in the system. SIL is a quantification of the magnitude of risk reduction.
Unlike hardware, software doesn't have well understood general failure-rate analysis mechanisms to determine the SIL for a system. The IEC 61508 standard recognizes this and instead requires different levels of engineering design and practice to ensure the quality of the software in the system. IEC 61508 provides recommendations to the design of the safety-critical system depending on SIL level. E.g. IEC 61508 highly recommends use of limited pointers in programs for SIL4.
IEC 61508 Part 3 (Software Requirements) provides clearly defined requirements for the software life cycle for "safety-related software" which applies to any software forming part of a safety-related system or used to develop a safety-related system within the scope of IEC 61508-1 and IEC 61508-2. Specific requirements exist for the language selection for development of safety-related software.
The following is an abbreviated summary of the relevant requirements for language selection:
7.4.1.3 states, "The third objective of the requirement is to select a suitable set of tools, including languages and compilers for the required safety integrity level, over the whole safety lifecycle of the software which assists verification, validation, assessment and modification"
7.4.2.4 states the language chosen shall possess features that "facilitate software modification such as modularity, information hiding and encapsulation"
7.4.4.2 is essentially a repeat of 7.4.1.3 covering the select of a suitable set of tools but more specifically spells out more detailed categories for use of tools including "automatic testing tools" and specifies the need for these tools to support the entire product lifecycle
7.4.4.3 states the requirements applied to the selection of programming language and calls for the selected language to: "be completely and unambiguously defined or restricted to unambiguously defined features" and "contain features that facilitate the detection of programming mistakes"
7.4.4.4 states that when the preceding requirement cannot be met by the chosen language a further justification is needed which details "the fitness of the language and any additional measures which address any identified shortcomings of the language"
Standards and best practise guidance on software development provide a means for consistent, controlled development. Standards can be particularly beneficial in the case of software for Safety-Critical Systems where high levels of safety and reliability must be achieved.
Software engineering is a wide-ranging discipline in general requiring expertise
in a number of related areas to ensure success. Software quality is of increasing
importance as the use of software becomes more pervasive. The
Software Engineering Institute (SEI) has developed a Capability Maturity Model (CMM) for assessing an organization's software process capability. The basic premise of CMM is: "The quality of a software system is governed by the quality of the process used to develop and maintain it"
The second half of the V-model focuses on verification and validation (testing) at each stage of development. In addition to straightforward requirements validation, developers must perform fault-injection testing at each level as well. Beyond stress testing, fault injection involves disrupting the system to induce a fault and verify that the safety-integrity requirements are met.
At the lowest level (unit or module testing), it's important to verify that the module responds appropriately to boundary values and out-of-range values. At this stage, it's especially important to verify that unexpected or uncommon execution paths are handled correctly. For example, verify that your CRC routine can indeed detect multiple-bit faults and out-of-order sequence faults.
As you integrate software (and hardware) modules, you must conduct further testing to verify their interaction and show that interfaces are operating as specified. Fault injections at this level might verify that one module responds properly when a second module rejects its input. This is also the stage at which you should validate diagnostics and monitoring software.
At the highest level, the system-validation plan must completely test each safety function and safety-integrity requirement. System-level validation should take place in as "life-like" an environment as possible. Here, fault injection can come in the form of communications faults or jabber, input loading, power, and environmental faults.
Formal methods are use of mathematical notations to describe systems. They are very highly reliable and dependable because they can "prove program behavior correctness using logic and mathematics" [12] and absolute proof can be given since it's based on maths.
Another major barrier in acceptance of formal methods is that many engineers and programmers do not have the appropriate training to make use of them and many managers do not know when and how they can be applied.
However this is gradually alleviated as:
Necessary mathematics and formal methods is being taught now in the universities.
New standards and drafts have begun to include formal methods for safety critical systems.
The use of formal methods in the future in the safety critical systems is very promising.
An issue which should exercise the mind of any supplier of a critical system is the question of exposure in law should the system fail.